{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "052838bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import db\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from serializer import GameState1DSerializer\n",
    "import sys\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import json\n",
    "import random as rd\n",
    "import agent_wrapper\n",
    "import randomAgents\n",
    "\n",
    "action_map = {}\n",
    "counter = 0\n",
    "\n",
    "for action in [\"attack\", \"move\"]:\n",
    "    for q in range(-14,15):\n",
    "        for r in range(-14, 15):\n",
    "            action_map[counter] = f\"{action},{q},{r}\"\n",
    "            counter += 1\n",
    "            \n",
    "\n",
    "action_map_inverse = {v:k for k,v in action_map.items()}\n",
    "\n",
    "#print(action_map, action_map_inverse)\n",
    "\n",
    "def prepare_training_data(from_timestamp = 0):\n",
    "    \n",
    "    if(isinstance(from_timestamp, dt.datetime)):\n",
    "        from_timestamp = int(from_timestamp.timestamp())\n",
    "        \n",
    "    replays = db.get_all_experiences({ \"time\": { \"$gt\": from_timestamp}})\n",
    "    \n",
    "    print(len(replays))\n",
    "    \n",
    "    def _get_score_from_state(state: dict):\n",
    "        \n",
    "        state = agent_wrapper.fix_state(state)\n",
    "        \n",
    "        \n",
    "        for key in [\"player1\", \"player2\", \"player3\", \"player4\"]:\n",
    "            if state[key][\"name\"] == \"JutricKafica1\":\n",
    "                return state[key][\"score\"] + state[key][\"health\"] + state[key][\"power\"]\n",
    "    \n",
    "    \n",
    "    rewards = [_get_score_from_state(replay[\"sp\"]) - _get_score_from_state(replay[\"s\"]) for replay in replays]\n",
    "\n",
    "    _seralizer = GameState1DSerializer()\n",
    "\n",
    "    serialized = [\n",
    "        _seralizer.serialize_single(x) for x in replays\n",
    "    ]\n",
    "    \n",
    "    actions = [\n",
    "        replay['a'] for replay in replays\n",
    "    ]\n",
    "\n",
    "    return serialized, rewards, actions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_targets(training_data, rewards, actions):\n",
    "    \n",
    "    n = len(training_data)\n",
    "    model_inputs = []\n",
    "    \n",
    "    for i in range(2, n):\n",
    "        model_inputs.append(np.hstack([training_data[i], training_data[i-1], training_data[i-2]]))\n",
    "    \n",
    "    states = model_inputs[:-1]\n",
    "    next_states = model_inputs[1:]\n",
    "    \n",
    "    return states, actions[2:-1], next_states, rewards[2:-1]\n",
    "    \n",
    "    \n",
    "\n",
    "class DQNAgent:\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        \n",
    "        print(type(state_size), type(action_size))\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_min = 0.1\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.update_rate = 300\n",
    "        \n",
    "        self.model = self._build_model(state_size, action_size)\n",
    "        self.target_model = self._build_model(state_size, action_size)\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        self.model.summary()\n",
    "        \n",
    "        self.last_updated = int((dt.datetime.now() - dt.timedelta(hours = 1)).timestamp())\n",
    "    \n",
    "    \n",
    "    def _build_model(self, state_size, action_size):\n",
    "        \n",
    "        # Define the model architecture\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Input(shape=(state_size,)))\n",
    "        model.add(keras.layers.Dense(128, activation='relu'))\n",
    "        model.add(keras.layers.Dense(64, activation='relu'))\n",
    "        model.add(keras.layers.Dense(action_size, activation='linear'))\n",
    "\n",
    "        # Compile the model with an optimizer and a loss function\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def act(self, state, state_json):\n",
    "        \n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            picked_random_valid = randomAgents.pick_rand_action(state_json)\n",
    "            return f\"{picked_random_valid[0]},{picked_random_valid[1]},{picked_random_valid[2]}\"\n",
    "        \n",
    "        act_values = self.model.predict(state)[0]\n",
    "        \n",
    "        for idx,elem in enumerate(act_values):\n",
    "            action = action_map[elem]\n",
    "            action_tokens = action.split(\",\")\n",
    "            if not randomAgents.is_valid_action(action_tokens[0], action_tokens[1], action_tokens[2], state_json):\n",
    "                act_values[idx] = 0\n",
    "        \n",
    "        return action_map[np.argmax(act_values[0])]  # Returns action using polic\n",
    "    \n",
    "    \n",
    "    def update(self):\n",
    "        \n",
    "        states, actions, next_states, rewards = create_targets(*prepare_training_data(self.last_updated))\n",
    "        \n",
    "        data = list(zip(states, actions, next_states, rewards))\n",
    "        \n",
    "        rd.shuffle(data)\n",
    "        \n",
    "        for datum in data:\n",
    "            \n",
    "            state = np.array(datum[0]).reshape(1, -1)\n",
    "            action = datum[1]\n",
    "            next_state = np.array(datum[2]).reshape(1,-1)\n",
    "            reward = datum[3]\n",
    "            \n",
    "            print(state.shape, next_state.shape, reward)\n",
    "            \n",
    "            print(state, action, next_state, reward)\n",
    "            \n",
    "            target = reward + self.gamma * np.amax(self.target_model.predict(next_state))\n",
    "            \n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action_map_invere(action)] = target\n",
    "            \n",
    "            self.model.fit(state, target_f, epochs=1, verbose = 0)\n",
    "            \n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "        self.last_updated = int(dt.datetime.now().timestamp())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "daa008d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Collection' object is not callable. If you meant to call the 'sort' method on a 'Collection' object it is failing because no such method exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     serialized \u001b[38;5;241m=\u001b[39m GameState1DSerializer()\u001b[38;5;241m.\u001b[39mserialize_single(one_document)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(serialized)\n\u001b[0;32m----> 6\u001b[0m agent \u001b[38;5;241m=\u001b[39m DQNAgent(\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mget_state_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mlen\u001b[39m(action_map))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#agent.update()\u001b[39;00m\n\u001b[1;32m     10\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mget_state_space\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_space\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     one_document \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfind_one()\n\u001b[1;32m      3\u001b[0m     serialized \u001b[38;5;241m=\u001b[39m GameState1DSerializer()\u001b[38;5;241m.\u001b[39mserialize_single(one_document)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(serialized)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pymongo/collection.py:3200\u001b[0m, in \u001b[0;36mCollection.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__name:\n\u001b[1;32m   3194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCollection\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object is not callable. If you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeant to call the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method on a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatabase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject it is failing because no such method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexists.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__name\n\u001b[1;32m   3199\u001b[0m     )\n\u001b[0;32m-> 3200\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3201\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCollection\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object is not callable. If you meant to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3202\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method on a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCollection\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object it is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailing because no such method exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3204\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Collection' object is not callable. If you meant to call the 'sort' method on a 'Collection' object it is failing because no such method exists."
     ]
    }
   ],
   "source": [
    "def get_state_space():\n",
    "    one_document = db.replay_buffer_collection.find_one()\n",
    "    serialized = GameState1DSerializer().serialize_single(one_document)\n",
    "    return len(serialized)\n",
    "\n",
    "agent = DQNAgent(3 * get_state_space(), len(action_map))\n",
    "\n",
    "#agent.update()\n",
    "\n",
    "train = False\n",
    "timestep = 0\n",
    "\n",
    "initial_obs = json.load(open(\"../initial_state.json\",'r'))\n",
    "\n",
    "obs_window = 3*[initial_obs]\n",
    "\n",
    "agent.update()\n",
    "\n",
    "while train:\n",
    "    \n",
    "    if timestep != 0 and timestep % agent.update_rate == 0:\n",
    "        agent.update()\n",
    "        \n",
    "    try:\n",
    "        state = np.hstack([GameState1DSerializer().serialize_single(x) for x in obs_window])\n",
    "    except:\n",
    "        from pprint import pprint\n",
    "        pprint(obs_window)\n",
    "\n",
    "    action = agent.act(state, obs_window[-1])\n",
    "    \n",
    "    print(action)\n",
    "    \n",
    "    _split = action.split(\",\")\n",
    "    mode = _split[0]\n",
    "    x = _split[1]\n",
    "    y = _split[2]\n",
    "\n",
    "    if mode == \"attack\":\n",
    "        info, success = agent_wrapper.attack(\"DQN\", obs_window[-1],x,y)\n",
    "    else:\n",
    "        info, success = agent_wrapper.move(\"DQN\", obs_window[-1],x,y)\n",
    "        \n",
    "    if(success):\n",
    "        new_obs = info\n",
    "        obs_window.append(new_obs)\n",
    "        del obs_window[0]\n",
    "\n",
    "        \n",
    "    timestep += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9225b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46613b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
